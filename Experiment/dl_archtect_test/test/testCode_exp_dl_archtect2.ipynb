{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd84a367",
   "metadata": {},
   "source": [
    "test code for deep learning archtects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a885b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import driverlessai\n",
    "driverlessai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcc0e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driverless AIのuser nameとpasswordの読み込み\n",
    "with open(os.path.join('..', '..', '..', 'idpass.json')) as f:\n",
    "    idpass = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a567d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dai_client(daiaddress, daipassword) -> 'driverlessai._core.Client':\n",
    "    '''\n",
    "    DAIサーバへの接続\n",
    "    ----------\n",
    "    daiaddress : str\n",
    "    daipassword : str\n",
    "    '''\n",
    "    print('----- start server connection : get_dai_client -----')\n",
    "    # Driverless AIサーバーへの接続\n",
    "    dai = driverlessai.Client(address=daiaddress, username=idpass['id'], password=daipassword)\n",
    "    return dai\n",
    "\n",
    "def get_dataset(daiobj, dataname, dataurl) -> 'driverlessai._datasets.Dataset': \n",
    "    '''\n",
    "    データオブジェクトの取得\n",
    "    ----------\n",
    "    daiobj : driverlessai._core.Client\n",
    "    dataname : str\n",
    "    dataurl : str\n",
    "    '''\n",
    "    print('----- start get data : get_dataset -----')\n",
    "    # DAI上のデータ一覧\n",
    "    uploaded_data = {i.name:i.key for i in daiobj.datasets.list()}\n",
    "    print('Uploaded data name : key >> ', uploaded_data)\n",
    "\n",
    "    # データ取得\n",
    "    if dataname in uploaded_data.keys():\n",
    "        print('Data is already uploaded in DAI')\n",
    "        ds = daiobj.datasets.get(uploaded_data[dataname]) \n",
    "    else:\n",
    "        print('Data is uploading to DAI.')\n",
    "        ds = daiobj.datasets.create(data=dataurl, data_source='s3')\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def get_experiment(daiobj, splitdata, target_column, task, drop_columns, tensorflow_image_pretrained_models, test_mode)-> 'driverlessai._experiments.Experiment':\n",
    "    '''\n",
    "    Experimentの実行とExperimentオブジェクトの取得\n",
    "    ----------\n",
    "    daiobj : driverlessai._core.Client\n",
    "    dataobj : driverlessai._datasets.Dataset\n",
    "    target_column : str\n",
    "    task : str\n",
    "    drop_columns : List[str]\n",
    "    '''\n",
    "    print('----- start experiment : get_experiment -----')\n",
    "    # Experiment設定    \n",
    "    dai_settings = {\n",
    "        'target_column': target_column,\n",
    "        'task': task,\n",
    "        'drop_columns': drop_columns,\n",
    "        'tensorflow_image_pretrained_models':[tensorflow_image_pretrained_models]\n",
    "    }\n",
    "    if test_mode:    # test modeの時、Acc=1&Time=1のExperimentを実施\n",
    "        dai_settings['accuracy'] = 1\n",
    "        dai_settings['time'] = 1\n",
    "    \n",
    "    # Experimentの実行\n",
    "    ex = daiobj.experiments.create(**splitdata, **dai_settings)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ff66ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whole_experiments(dai_address: str, dai_password: str, df_expperiments_info: pd.DataFrame) -> None:\n",
    "\n",
    "    # データ情報\n",
    "    data_name = df_expperiments_info['data_name'][0]\n",
    "    s3url = df_expperiments_info['s3url'][0]  # DAIにアップされてない場合の取得先S3\n",
    "    print('#####-----  利用データ: ', data_name, '  -----#####')\n",
    "\n",
    "    print('*************** DAIへ接続 ***************')\n",
    "    dai = get_dai_client(daiaddress=dai_address, daipassword=dai_password)\n",
    "    print(type(dai))\n",
    "    print('DAIバージョン: {}'.format(dai.server.version))\n",
    "\n",
    "    print('*************** データの取得 ***************')\n",
    "    ds = get_dataset(daiobj=dai, dataname=data_name, dataurl=s3url) \n",
    "\n",
    "    print(type(ds))\n",
    "    print('Dataサイズ(byte): {}'.format(ds.file_size))\n",
    "    print('Dataサイズ(mega byte): {}'.format(ds.file_size/1024**2))\n",
    "    print('Data shape: {}'.format(ds.shape))\n",
    "        \n",
    "    print('*************** データ分割 ***************')\n",
    "    ds_split = ds.split_to_train_test(train_size=0.75, train_name=data_name+'_train', test_name=data_name+'_test')\n",
    "    \n",
    "    \n",
    "    for _, row in df_expperiments_info.iterrows():\n",
    "        #**********  実験のパラメータ情報  **********#\n",
    "        tensorflow_image_pretrained_models = row['tensorflow_image_pretrained_models']\n",
    "        start_time = datetime.datetime.now().strftime('%Y年%m月%d日%H時%M分%S秒')\n",
    "        print('#####-----  開始時間: ', start_time, '  -----#####')\n",
    "        print('#####-----  archtect: ', tensorflow_image_pretrained_models, '  -----#####')\n",
    "        \n",
    "\n",
    "        # Experiment設定\n",
    "        target_column = row['target_column']\n",
    "        task = row['task']    # 'regression', 'classification', or 'unsupervised'\n",
    "        if row['drop_columns']  is np.nan:     # dropped clmを指定しない場合\n",
    "            drop_columns = []\n",
    "        else:\n",
    "            drop_columns = row['drop_columns'] .split(',')     # strをList化\n",
    "        #print(drop_columns)\n",
    "        test_mode = row['test_mode']\n",
    "        \n",
    "\n",
    "        print('*************** Experimentの実施 ***************')\n",
    "        ex = get_experiment(daiobj=dai, splitdata=ds_split, \n",
    "                            target_column=target_column, task=task, drop_columns=drop_columns, \n",
    "                           tensorflow_image_pretrained_models=tensorflow_image_pretrained_models, test_mode=test_mode)\n",
    "\n",
    "        print(type(ds))\n",
    "        print('学習時間（sec）：{}'.format(ex.run_duration))\n",
    "        print('学習時間（min）：{}'.format(ex.run_duration/60))\n",
    "        print('Experimentサイズ（byte）：{}'.format(ex.size))\n",
    "        print('Experimentサイズ（mega byte）：{}'.format(ex.size/1024**2))\n",
    "        print('精度：{}'.format(ex.metrics()))\n",
    "        print('********** Experiment Summary **********')\n",
    "        ex.summary()\n",
    "        \n",
    "        save_dict = dict(Data_Name=data_name,\n",
    "                         Try=row['try_n'],\n",
    "                         Datasize_mb = ds.file_size/1024**2,\n",
    "                         N_Observation = ds.shape[0],\n",
    "                         N_features = ds.shape[1] - len(drop_columns) - 1,\n",
    "                         Shape_Train = ds_split['train_dataset'].shape,\n",
    "                         Shape_Test = ds_split['test_dataset'].shape,\n",
    "                         Duration_min = ex.run_duration/60,\n",
    "                         Experiment_Size_mb = ex.size/1024**2,\n",
    "                         Acc_Time_Interpret = (ex.settings['accuracy'], ex.settings['time'], ex.settings['interpretability']),\n",
    "                         Metrics = ex.metrics()\n",
    "                        ) \n",
    "        with open('dlatest_{}.json'.format(start_time), 'w') as f:\n",
    "            json.dump(save_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48f99df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>try_n</th>\n",
       "      <th>data_name</th>\n",
       "      <th>s3url</th>\n",
       "      <th>target_column</th>\n",
       "      <th>task</th>\n",
       "      <th>drop_columns</th>\n",
       "      <th>enable_gpus</th>\n",
       "      <th>test_mode</th>\n",
       "      <th>tensorflow_image_pretrained_models</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>car_deals.zip</td>\n",
       "      <td>s3://h2o-public-test-data/bigdata/server/Image...</td>\n",
       "      <td>Price</td>\n",
       "      <td>regression</td>\n",
       "      <td>Manufacturer,Model,Year,Category,Mileage,FuelT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>resnet50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>car_deals.zip</td>\n",
       "      <td>s3://h2o-public-test-data/bigdata/server/Image...</td>\n",
       "      <td>Price</td>\n",
       "      <td>regression</td>\n",
       "      <td>Manufacturer,Model,Year,Category,Mileage,FuelT...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>seresnext50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   try_n      data_name                                              s3url  \\\n",
       "0      1  car_deals.zip  s3://h2o-public-test-data/bigdata/server/Image...   \n",
       "1      1  car_deals.zip  s3://h2o-public-test-data/bigdata/server/Image...   \n",
       "\n",
       "  target_column        task  \\\n",
       "0         Price  regression   \n",
       "1         Price  regression   \n",
       "\n",
       "                                        drop_columns  enable_gpus  test_mode  \\\n",
       "0  Manufacturer,Model,Year,Category,Mileage,FuelT...          NaN       True   \n",
       "1  Manufacturer,Model,Year,Category,Mileage,FuelT...          NaN       True   \n",
       "\n",
       "  tensorflow_image_pretrained_models  \n",
       "0                           resnet50  \n",
       "1                        seresnext50  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expperiments_info = pd.read_csv('exp_params_test.csv')\n",
    "df_expperiments_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acc01653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "try_n                                   int64\n",
       "data_name                              object\n",
       "s3url                                  object\n",
       "target_column                          object\n",
       "task                                   object\n",
       "drop_columns                           object\n",
       "enable_gpus                           float64\n",
       "test_mode                                bool\n",
       "tensorflow_image_pretrained_models     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expperiments_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2f04a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driverless AIサーバー情報\n",
    "dai_address = 'http://35.172.135.60'\n",
    "dai_password = idpass['pass11013gpu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bc67924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####-----  利用データ:  car_deals.zip   -----#####\n",
      "*************** DAIへ接続 ***************\n",
      "----- start server connection : get_dai_client -----\n",
      "<class 'driverlessai._core.Client'>\n",
      "DAIバージョン: 1.10.1.3\n",
      "*************** データの取得 ***************\n",
      "----- start get data : get_dataset -----\n",
      "Uploaded data name : key >>  {'histopathology_train.zip': '8ec3abf4-a407-11ec-8921-0242ac110002', 'car_deals.zip': '50119e5c-a407-11ec-8921-0242ac110002', 'UCI_Credit_Card3.csv': 'ac9c94bc-9f2d-11ec-ad99-0242ac110002', 'kaggle_train.csv': '056c70f0-9365-11ec-96ca-0242ac110002', 'talk4_customize_NLP検証用_h連携.csv': '9a306ad0-9364-11ec-96ca-0242ac110002', 'BostonHousing.csv': '6db78e82-91f9-11ec-a31a-0242ac110002'}\n",
      "Data is already uploaded in DAI\n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "Dataサイズ(byte): 785613764\n",
      "Dataサイズ(mega byte): 749.219669342041\n",
      "Data shape: (34571, 16)\n",
      "*************** データ分割 ***************\n",
      "Complete\n",
      "#####-----  開始時間:  2022年04月04日14時52分25秒   -----#####\n",
      "#####-----  archtect:  resnet50   -----#####\n",
      "*************** Experimentの実施 ***************\n",
      "----- start experiment : get_experiment -----\n",
      "Experiment launched at: http://35.172.135.60/#/experiment?key=68d2e408-b3db-11ec-8aea-0242ac110002\n",
      "Complete 100.00% - Status: Complete                                                \n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "学習時間（sec）：486.3615982532501\n",
      "学習時間（min）：8.10602663755417\n",
      "Experimentサイズ（byte）：1570449683\n",
      "Experimentサイズ（mega byte）：1497.697527885437\n",
      "精度：{'scorer': 'RMSE', 'val_score': 5764.826171875, 'val_score_sd': 131.37872314453125, 'val_roc_auc': None, 'val_pr_auc': None, 'test_score': 5333.71630859375, 'test_score_sd': 137.3572235107422, 'test_roc_auc': None, 'test_pr_auc': None}\n",
      "********** Experiment Summary **********\n",
      "Status: Complete\n",
      "Experiment: pogokaho (68d2e408-b3db-11ec-8aea-0242ac110002)\n",
      "  Version: 1.10.1.3, 2022-04-04 06:00\n",
      "  Settings: 1/1/8, seed=847700354, GPUs enabled\n",
      "  Train data: car_deals.zip_train (25928, 2)\n",
      "  Validation data: N/A\n",
      "  Test data: [Test] (8643, 1)\n",
      "  Target column: Price (regression, identity_noclip-transformed)\n",
      "System specs: Docker/Linux, 60 GB, 8 CPU cores, 1/1 GPU\n",
      "  Max memory usage: 4.45 GB, 8.51 GB GPU\n",
      "Recipe: AutoDL (4 iterations, 2 individuals)\n",
      "  Validation scheme: random, 1 internal holdout\n",
      "  Feature engineering: 100 features scored (100 selected)\n",
      "Timing: MOJO latency 83.6634 millis (98.9MB), Python latency 687.4714 millis (88.3MB)\n",
      "  Data preparation: 41.03 secs\n",
      "  Shift/Leakage detection: 0.01 secs\n",
      "  Model and feature tuning: 79.01 secs (5 models trained)\n",
      "  Feature evolution: 11.02 secs (4 models trained)\n",
      "  Final pipeline training: 230.82 secs (7 models trained)\n",
      "  Python / MOJO scorer building: 57.40 secs / 59.55 secs\n",
      "Validation score: RMSE = 6829.347 (constant preds of 6965)\n",
      "Validation score: RMSE = 5718.445 +/- 145.765 (baseline)\n",
      "Validation score: RMSE = 5764.826 +/- 131.3787 (final pipeline)\n",
      "Test score:       RMSE = 5333.716 +/- 137.3572 (final pipeline)\n",
      "#####-----  開始時間:  2022年04月04日15時00分41秒   -----#####\n",
      "#####-----  archtect:  seresnext50   -----#####\n",
      "*************** Experimentの実施 ***************\n",
      "----- start experiment : get_experiment -----\n",
      "Experiment launched at: http://35.172.135.60/#/experiment?key=905ae75e-b3dc-11ec-8aea-0242ac110002\n",
      "Complete 100.00% - Status: Complete                                                \n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "学習時間（sec）：506.9273347854614\n",
      "学習時間（min）：8.448788913091024\n",
      "Experimentサイズ（byte）：1571038259\n",
      "Experimentサイズ（mega byte）：1498.2588376998901\n",
      "精度：{'scorer': 'RMSE', 'val_score': 5778.541015625, 'val_score_sd': 139.8182830810547, 'val_roc_auc': None, 'val_pr_auc': None, 'test_score': 5296.58056640625, 'test_score_sd': 139.8182830810547, 'test_roc_auc': None, 'test_pr_auc': None}\n",
      "********** Experiment Summary **********\n",
      "Status: Complete\n",
      "Experiment: mokabupi (905ae75e-b3dc-11ec-8aea-0242ac110002)\n",
      "  Version: 1.10.1.3, 2022-04-04 06:09\n",
      "  Settings: 1/1/8, seed=718317371, GPUs enabled\n",
      "  Train data: car_deals.zip_train (25928, 2)\n",
      "  Validation data: N/A\n",
      "  Test data: [Test] (8643, 1)\n",
      "  Target column: Price (regression, identity_noclip-transformed)\n",
      "System specs: Docker/Linux, 60 GB, 8 CPU cores, 1/1 GPU\n",
      "  Max memory usage: 4.17 GB, 8.5 GB GPU\n",
      "Recipe: AutoDL (4 iterations, 2 individuals)\n",
      "  Validation scheme: random, 1 internal holdout\n",
      "  Feature engineering: 100 features scored (100 selected)\n",
      "Timing: MOJO latency 87.8899 millis (98.9MB), Python latency 681.6874 millis (88.3MB)\n",
      "  Data preparation: 46.12 secs\n",
      "  Shift/Leakage detection: 0.01 secs\n",
      "  Model and feature tuning: 103.12 secs (5 models trained)\n",
      "  Feature evolution: 11.46 secs (4 models trained)\n",
      "  Final pipeline training: 230.10 secs (7 models trained)\n",
      "  Python / MOJO scorer building: 50.17 secs / 58.12 secs\n",
      "Validation score: RMSE = 6829.347 (constant preds of 6965)\n",
      "Validation score: RMSE = 5826.694 +/- 175.0768 (baseline)\n",
      "Validation score: RMSE = 5778.541 +/- 139.8183 (final pipeline)\n",
      "Test score:       RMSE = 5296.581 +/- 139.8183 (final pipeline)\n"
     ]
    }
   ],
   "source": [
    "run_whole_experiments(dai_address=dai_address, dai_password=dai_password, df_expperiments_info=df_expperiments_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a5253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9649782a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
