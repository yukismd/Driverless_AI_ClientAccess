{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd84a367",
   "metadata": {},
   "source": [
    "test code for speed experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a885b106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1.3'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import driverlessai\n",
    "driverlessai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcc0e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driverless AIのuser nameとpasswordの読み込み\n",
    "with open(os.path.join('..', 'idpass.json')) as f:\n",
    "    idpass = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a57e3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dai_client(daiaddress, daipassword) -> 'driverlessai._core.Client':\n",
    "    '''\n",
    "    DAIサーバへの接続\n",
    "    ----------\n",
    "    daiaddress : str\n",
    "    daipassword : str\n",
    "    '''\n",
    "    print('----- start server connection : get_dai_client -----')\n",
    "    # Driverless AIサーバーへの接続\n",
    "    dai = driverlessai.Client(address=daiaddress, username=idpass['id'], password=daipassword)\n",
    "    return dai\n",
    "\n",
    "def get_dataset(daiobj, dataname, dataurl) -> 'driverlessai._datasets.Dataset': \n",
    "    '''\n",
    "    データオブジェクトの取得\n",
    "    ----------\n",
    "    daiobj : driverlessai._core.Client\n",
    "    dataname : str\n",
    "    dataurl : str\n",
    "    '''\n",
    "    print('----- start get data : get_dataset -----')\n",
    "    # DAI上のデータ一覧\n",
    "    uploaded_data = {i.name:i.key for i in daiobj.datasets.list()}\n",
    "    print('Uploaded data name : key >> ', uploaded_data)\n",
    "\n",
    "    # データ取得\n",
    "    if dataname in uploaded_data.keys():\n",
    "        print('Data is already uploaded in DAI')\n",
    "        ds = daiobj.datasets.get(uploaded_data[dataname]) \n",
    "    else:\n",
    "        print('Data is uploading to DAI.')\n",
    "        ds = daiobj.datasets.create(data=dataurl, data_source='s3')\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def get_experiment(daiobj, dataobj, target_column, task, drop_columns, enable_gpus) -> 'driverlessai._experiments.Experiment':\n",
    "    '''\n",
    "    Experimentの実行とExperimentオブジェクトの取得\n",
    "    ----------\n",
    "    daiobj : driverlessai._core.Client\n",
    "    dataobj : driverlessai._datasets.Dataset\n",
    "    target_column : str\n",
    "    task : str\n",
    "    drop_columns : List[str]\n",
    "    enable_gpus : bool\n",
    "    '''\n",
    "    print('----- start experiment : get_experiment -----')\n",
    "    # Experiment設定\n",
    "    dai_settings = {\n",
    "        'train_dataset': dataobj, \n",
    "        'target_column': target_column,\n",
    "        'task': task,\n",
    "        'drop_columns': drop_columns,\n",
    "        'enable_gpus': enable_gpus\n",
    "    }\n",
    "    # Experimentの実行\n",
    "    ex = daiobj.experiments.create(**dai_settings)\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a986fb25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>try_n</th>\n",
       "      <th>data_name</th>\n",
       "      <th>s3url</th>\n",
       "      <th>target_column</th>\n",
       "      <th>task</th>\n",
       "      <th>drop_columns</th>\n",
       "      <th>enable_gpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BostonHousing.csv</td>\n",
       "      <td>s3://h2oai-jp-public/sample_data/boston_house/...</td>\n",
       "      <td>MEDV</td>\n",
       "      <td>regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>UCI_Credit_Card3.csv</td>\n",
       "      <td>s3://h2oai-jp-public/sample_data/UCI_CreditCar...</td>\n",
       "      <td>default_payment_next_month</td>\n",
       "      <td>classification</td>\n",
       "      <td>ID,LIMIT_BAL</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   try_n             data_name  \\\n",
       "0      1     BostonHousing.csv   \n",
       "1      1  UCI_Credit_Card3.csv   \n",
       "\n",
       "                                               s3url  \\\n",
       "0  s3://h2oai-jp-public/sample_data/boston_house/...   \n",
       "1  s3://h2oai-jp-public/sample_data/UCI_CreditCar...   \n",
       "\n",
       "                target_column            task  drop_columns  enable_gpus  \n",
       "0                        MEDV      regression           NaN        False  \n",
       "1  default_payment_next_month  classification  ID,LIMIT_BAL        False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expperiments_info = pd.read_csv('../Management/spped_test/Experiments_Params.csv')\n",
    "df_expperiments_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d897bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "try_n             int64\n",
       "data_name        object\n",
       "s3url            object\n",
       "target_column    object\n",
       "task             object\n",
       "drop_columns     object\n",
       "enable_gpus        bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_expperiments_info.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5edf63ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####-----  開始時間:  2022年03月07日17時30分45秒   -----#####\n",
      "#####-----  利用データ:  BostonHousing.csv   -----#####\n",
      "#####-----  Try:  0   -----#####\n",
      "*************** DAIへ接続 ***************\n",
      "----- start server connection : get_dai_client -----\n",
      "<class 'driverlessai._core.Client'>\n",
      "DAIバージョン: 1.10.1.3\n",
      "*************** データの取得 ***************\n",
      "----- start get data : get_dataset -----\n",
      "Uploaded data name : key >>  {'UCI_Credit_Card3.csv': 'e04af12e-9dec-11ec-a1da-0242ac110002', 'walmart_ts_6_fcst_grp_train.csv': '4d2ad106-9b86-11ec-8e63-0242ac110002', 'walmart_ts_6_fcst_grp_test.csv': '4d2a15fe-9b86-11ec-8e63-0242ac110002', 'kaggle_train_index.csv': '7477e2b4-9369-11ec-ae6e-0242ac110002', 'kaggle_train2_int.csv': '757ae702-9368-11ec-ae6e-0242ac110002', 'BostonHousing.csv': '653b25c2-91de-11ec-8bed-0242ac110002'}\n",
      "Data is already uploaded in DAI\n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "Dataサイズ(byte): 57768\n",
      "Dataサイズ(mega byte): 0.05509185791015625\n",
      "Data shape: (506, 14)\n",
      "*************** Experimentの実施 ***************\n",
      "----- start experiment : get_experiment -----\n",
      "Experiment launched at: http://3.82.142.224/#/experiment?key=ea39bc52-9df0-11ec-a1da-0242ac110002\n",
      "Complete 100.00% - Status: Complete                                                       \n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "学習時間（sec）：360.14466428756714\n",
      "学習時間（min）：6.002411071459452\n",
      "Experimentサイズ（byte）：1119211709\n",
      "Experimentサイズ（mega byte）：1067.3634614944458\n",
      "********** Experiment Summary **********\n",
      "Status: Complete\n",
      "Experiment: gupihetu (ea39bc52-9df0-11ec-a1da-0242ac110002)\n",
      "  Version: 1.10.1.3, 2022-03-07 08:36\n",
      "  Settings: 7/2/8, seed=916919071, GPUs disabled\n",
      "  Train data: BostonHousing.csv (506, 14)\n",
      "  Validation data: N/A\n",
      "  Test data: N/A\n",
      "  Target column: MEDV (regression)\n",
      "System specs: Docker/Linux, 31 GB, 8 CPU cores, 0/0 GPU\n",
      "  Max memory usage: 0.734 GB, 0 GB GPU\n",
      "Recipe: AutoDL (23 iterations, 8 individuals)\n",
      "  Validation scheme: random, 6 internal holdouts (3-fold CV)\n",
      "  Feature engineering: 51 features scored (10 selected)\n",
      "Timing: MOJO latency 0.0393 millis (1.3MB), Python latency 119.9813 millis (661.1kB)\n",
      "  Data preparation: 6.14 secs\n",
      "  Shift/Leakage detection: 0.69 secs\n",
      "  Model and feature tuning: 65.88 secs (73 models trained)\n",
      "  Feature evolution: 215.06 secs (216 of 288 models trained)\n",
      "  Final pipeline training: 16.83 secs (6 models trained)\n",
      "  Python / MOJO scorer building: 33.49 secs / 17.35 secs\n",
      "Validation score: RMSE = 9.188011 (constant preds of 22.53)\n",
      "Validation score: RMSE = 3.972615 +/- 0.6370252 (baseline)\n",
      "Validation score: RMSE = 3.870511 +/- 0.5713101 (final pipeline)\n",
      "Test score:       RMSE = N/A\n",
      "#####-----  開始時間:  2022年03月07日17時37分02秒   -----#####\n",
      "#####-----  利用データ:  UCI_Credit_Card3.csv   -----#####\n",
      "#####-----  Try:  0   -----#####\n",
      "*************** DAIへ接続 ***************\n",
      "----- start server connection : get_dai_client -----\n",
      "<class 'driverlessai._core.Client'>\n",
      "DAIバージョン: 1.10.1.3\n",
      "*************** データの取得 ***************\n",
      "----- start get data : get_dataset -----\n",
      "Uploaded data name : key >>  {'UCI_Credit_Card3.csv': 'e04af12e-9dec-11ec-a1da-0242ac110002', 'walmart_ts_6_fcst_grp_train.csv': '4d2ad106-9b86-11ec-8e63-0242ac110002', 'walmart_ts_6_fcst_grp_test.csv': '4d2a15fe-9b86-11ec-8e63-0242ac110002', 'kaggle_train_index.csv': '7477e2b4-9369-11ec-ae6e-0242ac110002', 'kaggle_train2_int.csv': '757ae702-9368-11ec-ae6e-0242ac110002', 'BostonHousing.csv': '653b25c2-91de-11ec-8bed-0242ac110002'}\n",
      "Data is already uploaded in DAI\n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "Dataサイズ(byte): 3489056\n",
      "Dataサイズ(mega byte): 3.327423095703125\n",
      "Data shape: (30000, 25)\n",
      "*************** Experimentの実施 ***************\n",
      "----- start experiment : get_experiment -----\n",
      "Experiment launched at: http://3.82.142.224/#/experiment?key=c980a6be-9df1-11ec-a1da-0242ac110002\n",
      "Complete 100.00% - Status: Complete                                                      \n",
      "<class 'driverlessai._datasets.Dataset'>\n",
      "学習時間（sec）：210.65506267547607\n",
      "学習時間（min）：3.5109177112579344\n",
      "Experimentサイズ（byte）：1122157293\n",
      "Experimentサイズ（mega byte）：1070.172589302063\n",
      "********** Experiment Summary **********\n",
      "Status: Complete\n",
      "Experiment: sepivowi (c980a6be-9df1-11ec-a1da-0242ac110002)\n",
      "  Version: 1.10.1.3, 2022-03-07 08:40\n",
      "  Settings: 5/4/6, seed=1024925748, GPUs disabled\n",
      "  Train data: UCI_Credit_Card3.csv (30000, 23)\n",
      "  Validation data: N/A\n",
      "  Test data: N/A\n",
      "  Target column: default_payment_next_month (binary, 22.120% target class)\n",
      "System specs: Docker/Linux, 31 GB, 8 CPU cores, 0/0 GPU\n",
      "  Max memory usage: 0.706 GB, 0 GB GPU\n",
      "Recipe: AutoDL (23 iterations, 4 individuals)\n",
      "  Validation scheme: stratified, 1 internal holdout\n",
      "  Feature engineering: 81 features scored (24 selected)\n",
      "Timing: MOJO latency 0.0851 millis (1.7MB), Python latency 236.2779 millis (1.3MB)\n",
      "  Data preparation: 5.67 secs\n",
      "  Shift/Leakage detection: 1.03 secs\n",
      "  Model and feature tuning: 49.01 secs (14 of 16 models trained)\n",
      "  Feature evolution: 58.33 secs (20 of 84 models trained)\n",
      "  Final pipeline training: 34.54 secs (6 models trained)\n",
      "  Python / MOJO scorer building: 33.91 secs / 23.22 secs\n",
      "Validation score: AUC = 0.5 (constant preds of -1.258)\n",
      "Validation score: AUC = 0.7751225 +/- 0.004618311 (baseline)\n",
      "Validation score: AUC = 0.7787277 +/- 0.006398444 (final pipeline)\n",
      "Test score:       AUC = N/A\n"
     ]
    }
   ],
   "source": [
    "# Driverless AIサーバー情報\n",
    "dai_address = 'http://3.82.142.224'\n",
    "dai_password = idpass['pass11013']\n",
    "\n",
    "for _, row in df_expperiments_info.iterrows():\n",
    "    #**********  実験のパラメータ情報  **********#\n",
    "    # データ情報\n",
    "    data_name = row['data_name']\n",
    "    start_time = datetime.datetime.now().strftime('%Y年%m月%d日%H時%M分%S秒')\n",
    "    print('#####-----  開始時間: ', start_time, '  -----#####')\n",
    "    print('#####-----  利用データ: ', data_name, '  -----#####')\n",
    "    for exp_try in range(row['try_n']):\n",
    "        print('#####-----  Try: ', exp_try, '  -----#####')\n",
    "        s3url = row['s3url']  # DAIにアップされてない場合の取得先S3\n",
    "        # Experiment設定\n",
    "        target_column = row['target_column']\n",
    "        task = row['task']    # 'regression', 'classification', or 'unsupervised'\n",
    "        if row['drop_columns']  is np.nan:     # dropped clmを指定しない場合\n",
    "            drop_columns = []\n",
    "        else:\n",
    "            drop_columns = row['drop_columns'] .split(',')     # strをList化\n",
    "        #print(drop_columns)\n",
    "        enable_gpus = False\n",
    "\n",
    "\n",
    "        print('*************** DAIへ接続 ***************')\n",
    "        dai = get_dai_client(daiaddress=dai_address, daipassword=dai_password)\n",
    "        print(type(dai))\n",
    "        print('DAIバージョン: {}'.format(dai.server.version))\n",
    "\n",
    "\n",
    "        print('*************** データの取得 ***************')\n",
    "        ds = get_dataset(daiobj=dai, dataname=data_name, dataurl=s3url) \n",
    "\n",
    "        print(type(ds))\n",
    "        print('Dataサイズ(byte): {}'.format(ds.file_size))\n",
    "        print('Dataサイズ(mega byte): {}'.format(ds.file_size/1024**2))\n",
    "        print('Data shape: {}'.format(ds.shape))\n",
    "\n",
    "\n",
    "        print('*************** Experimentの実施 ***************')\n",
    "        ex = get_experiment(daiobj=dai, dataobj=ds, \n",
    "                            target_column=target_column, task=task, drop_columns=drop_columns, enable_gpus=enable_gpus)\n",
    "\n",
    "        print(type(ds))\n",
    "        print('学習時間（sec）：{}'.format(ex.run_duration))\n",
    "        print('学習時間（min）：{}'.format(ex.run_duration/60))\n",
    "        print('Experimentサイズ（byte）：{}'.format(ex.size))\n",
    "        print('Experimentサイズ（mega byte）：{}'.format(ex.size/1024**2))\n",
    "        print('********** Experiment Summary **********')\n",
    "        ex.summary()\n",
    "        \n",
    "        save_dict = dict(Data_Name=data_name,\n",
    "                 Try=row['try_n'],\n",
    "                 Datasize_mb = ds.file_size/1024**2,\n",
    "                 N_Observation = ds.shape[0],\n",
    "                 N_features = ds.shape[1] - len(drop_columns) - 1,\n",
    "                 Duration_min = ex.run_duration/60,\n",
    "                 Experiment_Size_mb = ex.size/1024**2,\n",
    "                 Acc_Time_Interpret = (ex.settings['accuracy'], ex.settings['time'], ex.settings['interpretability'])\n",
    "                )\n",
    "        with open('speedtest_{}.json'.format(start_time), 'w') as f:\n",
    "            json.dump(save_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e47ee88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05509185791015625\n",
      "506\n",
      "13\n",
      "4.029468584060669\n",
      "1073.3076963424683\n",
      "(5, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "log_dataname = data_name\n",
    "log_try_n = row['try_n']\n",
    "log_datasize_mb = ds.file_size/1024**2     # 元データサイズ（MB）\n",
    "log_n_observation = ds.shape[0]    # オブザベーション数\n",
    "log_n_features = ds.shape[1] - len(drop_columns) - 1    # 特徴量数\n",
    "log_duration_min = ex.run_duration/60    # 実行時間（分）\n",
    "log_expsize_mb = ex.size/1024**2     # Experimentサイズ（MB）\n",
    "log_accuracy_time_interpretability = ex.settings['accuracy'], ex.settings['time'], ex.settings['interpretability']   # accuracy, time, interpretability\n",
    "\n",
    "print(log_datasize_mb)\n",
    "print(log_n_observation)\n",
    "print(log_n_features)\n",
    "print(log_duration_min)\n",
    "print(log_expsize_mb)\n",
    "print(log_accuracy_time_interpretability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cb75860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Data_Name': 'BostonHousing.csv',\n",
       " 'Try': 1,\n",
       " 'Datasize_mb': 0.05509185791015625,\n",
       " 'N_Observation': 506,\n",
       " 'N_features': 13,\n",
       " 'Duration_min': 4.029468584060669,\n",
       " 'Experiment_Size_mb': 1073.3076963424683,\n",
       " 'Acc_Time_Interpret': (5, 4, 6)}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dict = dict(Data_Name=data_name,\n",
    "                 Try=row['try_n'],\n",
    "                 Datasize_mb = ds.file_size/1024**2,\n",
    "                 N_Observation = ds.shape[0],\n",
    "                 N_features = ds.shape[1] - len(drop_columns) - 1,\n",
    "                 Duration_min = ex.run_duration/60,\n",
    "                 Experiment_Size_mb = ex.size/1024**2,\n",
    "                 Acc_Time_Interpret = (ex.settings['accuracy'], ex.settings['time'], ex.settings['interpretability'])\n",
    "                )\n",
    "save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d213940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022年03月07日17時27分58秒\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now().strftime('%Y年%m月%d日%H時%M分%S秒')\n",
    "print(start_time)\n",
    "\n",
    "with open('speedtest_{}.json'.format(start_time), 'w') as f:\n",
    "    json.dump(save_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "423ade2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022年03月07日17時27分40秒'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime('%Y年%m月%d日%H時%M分%S秒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a35b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
